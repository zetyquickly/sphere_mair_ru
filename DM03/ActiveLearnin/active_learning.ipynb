{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import  tqdm\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fucntion that we try to approximate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[1]*x[6] + x[8]/x[9]*np.sqrt(x[6]/x[7]) + (np.pi)*np.sqrt(x[2]) + 1/np.sin(x[3]) + np.log(x[2]+x[4]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INIT_COUNT = 2000\n",
    "COUNT_TO_ADD = 50\n",
    "TOT_SIZE = 1000000\n",
    "PATH_TO_DATA = \"/home/emil/all/public.data\"\n",
    "TARGET = np.zeros(TOT_SIZE)\n",
    "list_of_initial_index = []\n",
    "GDR = GradientBoostingRegressor(n_estimators =150, learning_rate = 0.075)\n",
    "sample = pd.read_csv(\"/home/emil/all/public.sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(PATH_TO_DATA, \n",
    "                   sep= \" \", \n",
    "                   names=[\"feature_{}\".format(i) for i in range(0, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.401877</td>\n",
       "      <td>3.943829</td>\n",
       "      <td>7.830992</td>\n",
       "      <td>7.984400</td>\n",
       "      <td>9.116474</td>\n",
       "      <td>1.975514</td>\n",
       "      <td>3.352228</td>\n",
       "      <td>7.682296</td>\n",
       "      <td>2.777747</td>\n",
       "      <td>5.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.773971</td>\n",
       "      <td>6.288709</td>\n",
       "      <td>3.647845</td>\n",
       "      <td>5.134009</td>\n",
       "      <td>9.522297</td>\n",
       "      <td>9.161951</td>\n",
       "      <td>6.357117</td>\n",
       "      <td>7.172969</td>\n",
       "      <td>1.416026</td>\n",
       "      <td>6.069689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.163006</td>\n",
       "      <td>2.428868</td>\n",
       "      <td>1.372316</td>\n",
       "      <td>8.041768</td>\n",
       "      <td>1.566791</td>\n",
       "      <td>4.009444</td>\n",
       "      <td>1.297904</td>\n",
       "      <td>1.088088</td>\n",
       "      <td>9.989245</td>\n",
       "      <td>2.182569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.129324</td>\n",
       "      <td>8.391122</td>\n",
       "      <td>6.126398</td>\n",
       "      <td>2.960316</td>\n",
       "      <td>6.375523</td>\n",
       "      <td>5.242872</td>\n",
       "      <td>4.935830</td>\n",
       "      <td>9.727750</td>\n",
       "      <td>2.925168</td>\n",
       "      <td>7.713577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.267450</td>\n",
       "      <td>7.699138</td>\n",
       "      <td>4.002286</td>\n",
       "      <td>8.915295</td>\n",
       "      <td>2.833147</td>\n",
       "      <td>3.524583</td>\n",
       "      <td>8.077245</td>\n",
       "      <td>9.190265</td>\n",
       "      <td>0.697553</td>\n",
       "      <td>9.493271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   8.401877   3.943829   7.830992   7.984400   9.116474   1.975514   \n",
       "1   4.773971   6.288709   3.647845   5.134009   9.522297   9.161951   \n",
       "2   0.163006   2.428868   1.372316   8.041768   1.566791   4.009444   \n",
       "3   5.129324   8.391122   6.126398   2.960316   6.375523   5.242872   \n",
       "4   5.267450   7.699138   4.002286   8.915295   2.833147   3.524583   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  \n",
       "0   3.352228   7.682296   2.777747   5.539700  \n",
       "1   6.357117   7.172969   1.416026   6.069689  \n",
       "2   1.297904   1.088088   9.989245   2.182569  \n",
       "3   4.935830   9.727750   2.925168   7.713577  \n",
       "4   8.077245   9.190265   0.697553   9.493271  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First init 2000 points to start active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_initial_index = []\n",
    "\n",
    "for _ in range(INIT_COUNT):\n",
    "    now_ind = np.random.randint(TOT_SIZE)\n",
    "    list_of_initial_index.append(now_ind)\n",
    "\n",
    "\n",
    "for i in range(INIT_COUNT):\n",
    "    temp_pont = np.array(data.iloc[list_of_initial_index[i]])\n",
    "    value = func(temp_pont)\n",
    "    TARGET[list_of_initial_index[i]] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of training data: 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Len of training data: {}\".\n",
    "      format(len(np.unique(list_of_initial_index))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inde = 0\n",
    "\n",
    "new_final_ind = np.unique(list_of_initial_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_target(new_ind, target):\n",
    "    for ind in new_ind:\n",
    "        temp_pont = np.array(data.iloc[ind])\n",
    "        value = func(temp_pont)\n",
    "        target[ind] = value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_final_ind = list(new_final_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 0 step is: 2150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [03:50<44:49,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 100 step is: 7150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [09:51<51:46,  3.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 200 step is: 12150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [17:19<58:16,  4.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 300 step is: 17150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [27:01<1:01:49,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 400 step is: 22150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [38:26<59:25,  7.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 500 step is: 27150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [51:20<55:15,  8.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 600 step is: 32150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [1:06:07<46:51,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 700 step is: 37150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [1:23:28<35:43, 10.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 800 step is: 42150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [1:42:22<19:39, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TARGET on 900 step is: 47150\n",
      "Making submit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:03:22<00:00, 13.06s/it]\n"
     ]
    }
   ],
   "source": [
    "MAIN_REG = GradientBoostingRegressor(n_estimators =150, learning_rate = 0.075)\n",
    "ERR_REG = GradientBoostingRegressor(n_estimators =150, learning_rate = 0.075)\n",
    "\n",
    "for KDP in tqdm(range(1000)):\n",
    "    inde+=1\n",
    "    #Get the spread of predictions of the algorithm committee.\n",
    "    \n",
    "    #print(\"Len of training data: {}\".\n",
    "      #format(len(new_final_ind))\n",
    "    \n",
    "    X_train_new = data.iloc[new_final_ind]\n",
    "    y_train_new = TARGET[new_final_ind]\n",
    "    \n",
    "    #print(\"Fitting algorithm\")\n",
    "    MAIN_REG.fit(X_train_new, y_train_new)\n",
    "    pred = MAIN_REG.predict(X_train_new)\n",
    "    \n",
    "    #Looking for points with max-size errors\n",
    "    \n",
    "    err = np.abs(pred - y_train_new)\n",
    "    #print(\"Fitting algorithm on errors\")\n",
    "   \n",
    "    ERR_REG.fit(X_train_new, err)\n",
    "    pred_errs = np.abs(ERR_REG.predict(data))\n",
    "    pred_errs[new_final_ind] = 0 \n",
    "    \n",
    "    #print(\"Getting points with max errors\")\n",
    "    new_ind = pred_errs.argsort()[::-1][:COUNT_TO_ADD]\n",
    "     \n",
    "    \n",
    "    #print(\"Getting new target values\")\n",
    "    \n",
    "    fill_target(new_ind, TARGET)\n",
    "    new_final_ind = list(np.unique(new_final_ind + list(new_ind)))\n",
    "    \n",
    "            \n",
    "            \n",
    "    if (KDP % 100 == 0):\n",
    "        print(\"Size of TARGET on {} step is: {}\".\\\n",
    "              format(KDP, len(TARGET[TARGET!=0])))\n",
    "        \n",
    "        print(\"Making submit\")\n",
    "        \n",
    "        sample.Expected = MAIN_REG.predict(data)\n",
    "\n",
    "        sample.to_csv(\"sub_{}\".format(KDP), index = False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['error.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(MAIN_REG, 'model.pkl')\n",
    "joblib.dump(ERR_REG, 'error.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv(\"/home/emil/Downloads/private/private.data\", \n",
    "                   sep= \" \", \n",
    "                   names=[\"feature_{}\".format(i) for i in range(0, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.33423554949659"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(data)\n",
    "with open(\"subm5\", \"w\") as f:\n",
    "    f.write(\"Id,Expected\\n\")\n",
    "    for idx, value in enumerate(result):\n",
    "        f.write(str(idx+1)+\",\"+str(value)+\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/emil/anaconda2/envs/python3/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = joblib.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
